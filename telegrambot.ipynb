{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install python-dotenv aiogram==2.5\n",
    "!pip -q install openai==0.28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting echo_bot.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile echo_bot.py\n",
    "\n",
    "#search botfather\n",
    "#/newbot\n",
    "#set name of bot \n",
    "#give bot username_bot\n",
    "#click on url provided by botfather\n",
    "from aiogram import Bot, Dispatcher, executor, types\n",
    "import os \n",
    "from dotenv import load_dotenv\n",
    "import logging\n",
    "\n",
    "load_dotenv()\n",
    "API_TOKEN=os.getenv('TOKEN')\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "#initialize the bot\n",
    "bot=Bot(API_TOKEN)\n",
    "dp=Dispatcher(bot)\n",
    "\n",
    "@dp.message_handler(commands=['start','help'])\n",
    "async def command_start_handler(message: types.Message):\n",
    "    \"\"\"\n",
    "    this handler receives messages with /start or /help commands\n",
    "    \n",
    "    \"\"\"\n",
    "    await message.reply(\"Hi\\n i am an echobot powered by \\n AIogram \")\n",
    "\n",
    "\n",
    "\n",
    "@dp.message_handler()\n",
    "async def echo(message: types.Message):\n",
    "    \"\"\" \n",
    "    This will return echo message\n",
    "    \"\"\"\n",
    "    await message.reply(message.text)\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    executor.start_polling(dp, skip_updates=True)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mybot.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mybot.py\n",
    "from aiogram import Bot, Dispatcher, executor, types\n",
    "import os \n",
    "from dotenv import load_dotenv\n",
    "import logging\n",
    "import openai\n",
    "\n",
    "load_dotenv()\n",
    "TOKEN=os.getenv('TOKEN')\n",
    "OPENAI_API_KEY=os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "openai.api_key = OPENAI_API_KEY\n",
    "\n",
    "MODEL_NAME='gpt-3.5-turbo'\n",
    "\n",
    "bot=Bot(token=TOKEN)\n",
    "dispatcher=Dispatcher(bot)\n",
    "\n",
    "class Reference:\n",
    "    def __init__(self):\n",
    "        self.response=\"\"\n",
    "\n",
    "\n",
    "reference=Reference()\n",
    "def clear_past():\n",
    "    reference.response=\"\"\n",
    "\n",
    "@dispatcher.message_handler(commands=['start'])\n",
    "async def command_start_handler(message:types.Message):\n",
    "    await message.reply(\"I am a Chatbot created by Satyake. How may i assist?\")\n",
    "\n",
    "\n",
    "@dispatcher.message_handler(commands=['help'])\n",
    "async def helper(message:types.Message):\n",
    "    help_command=\"\"\"\n",
    "    Hi there, i am a bot created by Satyake. Please follow the commands-\n",
    "    /start- to start the conversation\n",
    "    /clear- to clear the previous response\n",
    "    /help- to see the help menu\n",
    "    I hope this helps\n",
    "    \"\"\"\n",
    "    await message.reply(help_command)\n",
    "\n",
    "@dispatcher.message_handler(commands=['clear'])\n",
    "async def clear(message:types.Message):\n",
    "    clear_past()\n",
    "    await message.reply('Previous response cleared!')\n",
    "\n",
    "@dispatcher.message_handler()\n",
    "async def main_bot(message:types.Message):\n",
    "    \"\"\" handler for integration of Open ai\"\"\"\n",
    "    print(f\">>> USER: \\n\\t {message.text}\")\n",
    "    response=openai.ChatCompletion.create(\n",
    "        model=MODEL_NAME,\n",
    "        messages=[\n",
    "            {'role': \"system\",'content': \"you are a transformers robot like from the movie Transformers, You have to speak like that\"},\n",
    "            {\"role\": \"assistant\",\"content\": reference.response},\n",
    "            {\"role\": \"user\",\"content\": message.text}\n",
    "        ]\n",
    "    )\n",
    "    reference.response=response['choices'][0]['message']['content']\n",
    "    print(f\"<<< chatGPT: \\n\\t{reference.response}\")\n",
    "    await bot.send_message(chat_id=message.chat.id, text=reference.response)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    executor.start_polling(dispatcher, skip_updates=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
